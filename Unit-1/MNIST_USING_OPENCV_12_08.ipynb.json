{"cells":[{"cell_type":"code","execution_count":1,"id":"12775242-545c-4c08-af10-6b245a1085a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53229,"status":"ok","timestamp":1762401340051,"user":{"displayName":"BACKIYADHARSHAN V 23ADL192","userId":"15586347546058572160"},"user_tz":-330},"id":"12775242-545c-4c08-af10-6b245a1085a9","outputId":"a64d305d-6f2c-4c60-ea09-b38c240c84f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.4737\n","Epoch 2/3\n","\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.1143\n","Epoch 3/3\n","\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0724\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n","from tensorflow.keras.utils import normalize as normalize\n","mnist = tf.keras.datasets.mnist  # Load MNIST dataset into the cod\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = normalize(x_train, axis=1)\n","x_test = normalize(x_test, axis=1)\n","model = Sequential()\n","model.add(Flatten(input_shape=(28, 28)));\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_train, y_train, epochs=3)\n","model.save('handwrittenRecognition.keras')"]},{"cell_type":"code","metadata":{"id":"1865d8a3"},"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n","from tensorflow.keras.utils import normalize as normalize\n","mnist = tf.keras.datasets.mnist  # Load MNIST dataset into the cod\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = normalize(x_train, axis=1)\n","x_test = normalize(x_test, axis=1)\n","model = Sequential()\n","model.add(Flatten(input_shape=(28, 28)));\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_train, y_train, epochs=3)\n","model.save('handwrittenRecognition.keras')\n","\n","model = tf.keras.models.load_model('handwrittenRecognition.keras')\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Loss : \", loss)\n","print(\"Accuracy : \", accuracy)\n","image_number = 0\n","while os.path.isfile(f\"D:/KONGU_KEC/Image and Video Analytics/Unit-1/Programs/HandWritten-Digits/digit{image_number}.png\"):\n","    try:\n","        img = cv2.imread(f\"D:/KONGU_KEC/Image and Video Analytics/Unit-1/Programs/HandWritten-Digits/digit{image_number}.png\")[:,:,0]\n","        img = np.invert(np.array([img]))\n","        prediction = model.predict(img)\n","        print(\"The number is probably a {}\".format(np.argmax(prediction)))\n","        plt.imshow(img[0], cmap=plt.cm.binary)\n","        plt.show()\n","    except:\n","        print(\"Error reading image! Proceeding to the next one...\")\n","    finally:\n","        image_number += 1"],"id":"1865d8a3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f3a11f4d-a024-4b22-be9a-717d2b8618a8","metadata":{"id":"f3a11f4d-a024-4b22-be9a-717d2b8618a8"},"outputs":[],"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":null,"id":"62357d79-3c90-4913-b1da-be45540602ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1558,"status":"ok","timestamp":1761137681139,"user":{"displayName":"Aadhithya Aadhi","userId":"11458270024157658895"},"user_tz":-330},"id":"62357d79-3c90-4913-b1da-be45540602ed","outputId":"0cd04281-e731-4def-c9cf-eb6522320a4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 52.8086\n","Loss :  45.95963668823242\n","Accuracy :  0.9621999859809875\n"]}],"source":["model = tf.keras.models.load_model('handwrittenRecognition.keras')\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Loss : \", loss)\n","print(\"Accuracy : \", accuracy)\n","image_number = 0\n","while os.path.isfile(f\"D:/KONGU_KEC/Image and Video Analytics/Unit-1/Programs/HandWritten-Digits/digit{image_number}.png\"):\n","    try:\n","        img = cv2.imread(f\"D:/KONGU_KEC/Image and Video Analytics/Unit-1/Programs/HandWritten-Digits/digit{image_number}.png\")[:,:,0]\n","        img = np.invert(np.array([img]))\n","        prediction = model.predict(img)\n","        print(\"The number is probably a {}\".format(np.argmax(prediction)))\n","        plt.imshow(img[0], cmap=plt.cm.binary)\n","        plt.show()\n","    except:\n","        print(\"Error reading image! Proceeding to the next one...\")\n","    finally:\n","        image_number += 1"]},{"cell_type":"code","execution_count":null,"id":"68fa37ac-8bed-4907-91a0-4d1c1544f356","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68fa37ac-8bed-4907-91a0-4d1c1544f356","executionInfo":{"status":"error","timestamp":1761137684248,"user_tz":-330,"elapsed":463,"user":{"displayName":"Aadhithya Aadhi","userId":"11458270024157658895"}},"outputId":"42f0edd2-8a53-4076-8300-c42218a55b50"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'D:/mnist-20250819T061711Z-1-001/mnist/0'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1218888483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/mnist-20250819T061711Z-1-001/mnist/0'"]}],"source":["import os\n","import numpy as np\n","import shutil\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","import keras\n","\n","# -------------------------------\n","# STEP 1: DEFINE DATA DIRECTORY\n","# -------------------------------\n","output_dir = \"D:/mnist-20250819T061711Z-1-001/mnist\" # <--- **UPDATE THIS PATH**\n","\n","# -------------------------------\n","# STEP 2: LOAD DATASET\n","# -------------------------------\n","img_size = 64\n","num_classes = 10\n","\n","X, y = [], []\n","\n","for label in range(num_classes):\n","    class_dir = os.path.join(output_dir, str(label))\n","    for img_name in os.listdir(class_dir):\n","        img_path = os.path.join(class_dir, img_name)\n","        img = load_img(img_path, target_size=(img_size, img_size))\n","        img_array = img_to_array(img) / 255.0  # normalize [0,1]\n","        X.append(img_array)\n","        y.append(label)\n","\n","X = np.array(X)\n","y = to_categorical(y, num_classes)\n","\n","print(\"âœ… Dataset loaded:\", X.shape, y.shape)\n","\n","# -------------------------------\n","# STEP 3: TRAIN-TEST SPLIT\n","# -------------------------------\n","x_train, x_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","input_shape = (img_size, img_size, 3)\n","batch_size = 32\n","epochs = 15\n","\n","# -------------------------------\n","# STEP 4: BUILD MODEL\n","# -------------------------------\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(\n","    loss=keras.losses.categorical_crossentropy,\n","    optimizer=keras.optimizers.Adadelta(),\n","    metrics=['accuracy']\n",")\n","\n","# -------------------------------\n","# STEP 5: TRAIN MODEL\n","# -------------------------------\n","print(\"ğŸš€ Training started...\")\n","hist = model.fit(\n","    x_train, y_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    verbose=1,\n","    validation_data=(x_test, y_test)\n",")\n","\n","print(\"âœ… The model has successfully trained!\")\n","\n","# -------------------------------\n","# STEP 6: EVALUATE MODEL\n","# -------------------------------\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"ğŸ“Š Test loss:\", score[0])\n","print(\"ğŸ“Š Test accuracy:\", score[1])\n","\n","# -------------------------------\n","# STEP 7: PLOT TRAINING HISTORY\n","# -------------------------------\n","plt.figure(figsize=(12,5))\n","\n","# Accuracy\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['accuracy'], label='Train Acc')\n","plt.plot(hist.history['val_accuracy'], label='Val Acc')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Loss\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['loss'], label='Train Loss')\n","plt.plot(hist.history['val_loss'], label='Val Loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"Jiu7kIFp6RyH"},"id":"Jiu7kIFp6RyH","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pSM_JO5h6Rco"},"id":"pSM_JO5h6Rco","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":5}